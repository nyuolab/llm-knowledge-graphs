# llm-knowledge-graphs
Code repository for our paper, "Medical Large Language Models are Vulnerable to Data Poisoning Attacks" (Nature Medicine, 2024).
